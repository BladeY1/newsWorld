{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains import create_structured_output_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.chains import create_structured_output_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "dog_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"record_dog\",\n",
    "        \"description\": \"Record some identifying information about a dog.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"description\": \"The dog's name\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"color\": {\n",
    "                    \"description\": \"The dog's color\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"fav_food\": {\n",
    "                    \"description\": \"The dog's favorite food\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\", \"color\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "structured_llm = create_structured_output_runnable(\n",
    "    dog_schema,\n",
    "    llm,\n",
    "    mode=\"openai-tools\",\n",
    "    enforce_function_usage=True,\n",
    ")\n",
    "res = structured_llm.invoke(\"Harry was a chubby brown beagle who loved chicken\")\n",
    "print(res)\n",
    "# -> {'name': 'Harry', 'color': 'brown', 'fav_food': 'chicken'}\n",
    "# -> RecordDog(name=\"Harry\", color=\"brown\", fav_food=\"chicken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"2024-06-13T12:00:00Z\", \"event\": \"AgentWantsUpdatedStateEvent\", \"details\": {\"sender_id\": null}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"created_at\": \"2024-06-13T12:00:00Z\",  # Example timestamp\n",
    "    \"event\": \"AgentWantsUpdatedStateEvent\",\n",
    "    \"details\": {\"sender_id\": None}  # Assuming `sender_id` should have a value\n",
    "}\n",
    "\n",
    "print(json.dumps(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': {'data': {}, 'raw': '<json={\"player\": {\"song\": [], \"artist\": [\"paul simon\", \"led zeppelin\", \"the doors\"]}}}</json>', 'errors': [], 'validated_data': {}}}\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains import create_structured_output_runnable\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "\n",
    "from kor import create_extraction_chain, Object, Text \n",
    "\n",
    "schema = Object(\n",
    "    id=\"player\",\n",
    "    description=(\n",
    "        \"User is controlling a music player to select songs, pause or start them or play\"\n",
    "        \" music by a particular artist.\"\n",
    "    ),\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"song\",\n",
    "            description=\"User wants to play this song\",\n",
    "            examples=[],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"album\",\n",
    "            description=\"User wants to play this album\",\n",
    "            examples=[],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"artist\",\n",
    "            description=\"Music by the given artist\",\n",
    "            examples=[(\"Songs by paul simon\", \"paul simon\")],\n",
    "            many=True,\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"action\",\n",
    "            description=\"Action to take one of: `play`, `stop`, `next`, `previous`.\",\n",
    "            examples=[\n",
    "                (\"Please stop the music\", \"stop\"),\n",
    "                (\"play something\", \"play\"),\n",
    "                (\"play a song\", \"play\"),\n",
    "                (\"next song\", \"next\"),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    many=False,\n",
    ")\n",
    "\n",
    "chain = create_extraction_chain(llm, schema, encoder_or_encoder_class='json')\n",
    "res = chain.invoke(\"play songs by paul simon and led zeppelin and the doors\")\n",
    "player_data = res['text']['data']['player']\n",
    "print(player_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=ExtractionPromptTemplate(input_variables=['text'], output_parser=KorParser(encoder=<kor.encoders.json_data.JSONEncoder object at 0x7f39bf41ae90>, schema_=Object(id='musicrequest', description='', many=False, attributes=[Text(id='song', description='The song(s) that the user would like to be played.', many=True, examples=()), Text(id='album', description='The album(s) that the user would like to be played.', many=True, examples=()), Text(id='artist', description='The artist(s) whose music the user would like to hear.', many=True, examples=[('Songs by paul simon', 'paul simon')]), Selection(id='action', description='The action that should be taken; one of `play`, `stop`, `next`, `previous`', many=False, options=[Option(id='play', description='', many=False, examples=()), Option(id='stop', description='', many=False, examples=()), Option(id='previous', description='', many=False, examples=()), Option(id='next', description='', many=False, examples=())], examples=[('Please stop the music', 'stop'), ('play something', 'play'), ('play a song', 'play'), ('next song', 'next')], null_examples=())], examples=()), validator=<kor.validators.PydanticValidator object at 0x7f39bf518390>), encoder=<kor.encoders.json_data.JSONEncoder object at 0x7f39bf41ae90>, node=Object(id='musicrequest', description='', many=False, attributes=[Text(id='song', description='The song(s) that the user would like to be played.', many=True, examples=()), Text(id='album', description='The album(s) that the user would like to be played.', many=True, examples=()), Text(id='artist', description='The artist(s) whose music the user would like to hear.', many=True, examples=[('Songs by paul simon', 'paul simon')]), Selection(id='action', description='The action that should be taken; one of `play`, `stop`, `next`, `previous`', many=False, options=[Option(id='play', description='', many=False, examples=()), Option(id='stop', description='', many=False, examples=()), Option(id='previous', description='', many=False, examples=()), Option(id='next', description='', many=False, examples=())], examples=[('Please stop the music', 'stop'), ('play something', 'play'), ('play a song', 'play'), ('next song', 'next')], null_examples=())], examples=()), type_descriptor=<kor.type_descriptors.TypeScriptDescriptor object at 0x7f39c41a3510>, instruction_template=PromptTemplate(input_variables=['format_instructions', 'type_description'], template=\"Your goal is to extract structured information from the user's input that matches the form described below. When extracting information please make sure it matches the type information exactly. Do not add any attributes that do not appear in the schema shown below.\\n\\n{type_description}\\n\\n{format_instructions}\\n\\n\")) llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f39bf7e5490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f39bf449890>, model_name='llama3', openai_api_key=SecretStr('**********'), openai_api_base='http://localhost:11434/v1', openai_proxy='') output_parser=KorParser(encoder=<kor.encoders.json_data.JSONEncoder object at 0x7f39bf41ae90>, schema_=Object(id='musicrequest', description='', many=False, attributes=[Text(id='song', description='The song(s) that the user would like to be played.', many=True, examples=()), Text(id='album', description='The album(s) that the user would like to be played.', many=True, examples=()), Text(id='artist', description='The artist(s) whose music the user would like to hear.', many=True, examples=[('Songs by paul simon', 'paul simon')]), Selection(id='action', description='The action that should be taken; one of `play`, `stop`, `next`, `previous`', many=False, options=[Option(id='play', description='', many=False, examples=()), Option(id='stop', description='', many=False, examples=()), Option(id='previous', description='', many=False, examples=()), Option(id='next', description='', many=False, examples=())], examples=[('Please stop the music', 'stop'), ('play something', 'play'), ('play a song', 'play'), ('next song', 'next')], null_examples=())], examples=()), validator=<kor.validators.PydanticValidator object at 0x7f39bf518390>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': {'data': {'musicrequest': {'action': 'stop'}},\n",
       "  'raw': '<json>{\"musicrequest\": {\"action\": \"stop\"}}</json>',\n",
       "  'errors': [],\n",
       "  'validated_data': MusicRequest(song=None, album=None, artist=None, action=<Action.stop: 'stop'>)}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import enum\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text, Number\n",
    "import pydantic\n",
    "from typing import List\n",
    "from kor import from_pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "\n",
    "class Action(enum.Enum):\n",
    "    play = \"play\"\n",
    "    stop = \"stop\"\n",
    "    previous = \"previous\"\n",
    "    next_ = \"next\"\n",
    "\n",
    "\n",
    "class MusicRequest(BaseModel):\n",
    "    song: Optional[List[str]] = Field(\n",
    "        default=None, description=\"The song(s) that the user would like to be played.\"\n",
    "    )\n",
    "    album: Optional[List[str]] = Field(\n",
    "        default=None, description=\"The album(s) that the user would like to be played.\"\n",
    "    )\n",
    "    artist: Optional[List[str]] = Field(\n",
    "        default=None,\n",
    "        description=\"The artist(s) whose music the user would like to hear.\",\n",
    "        examples=[(\"Songs by paul simon\", \"paul simon\")],\n",
    "    )\n",
    "    action: Optional[Action] = Field(\n",
    "        default=None,\n",
    "        description=\"The action that should be taken; one of `play`, `stop`, `next`, `previous`\",\n",
    "        examples=[\n",
    "            (\"Please stop the music\", \"stop\"),\n",
    "            (\"play something\", \"play\"),\n",
    "            (\"play a song\", \"play\"),\n",
    "            (\"next song\", \"next\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "schema, validator = from_pydantic(MusicRequest)\n",
    "chain = create_extraction_chain(\n",
    "    llm, schema, encoder_or_encoder_class=\"json\", validator=validator\n",
    ")\n",
    "print(chain)\n",
    "#print(chain.prompt.format_prompt(text=\"[user input]\").to_string())\n",
    "chain.invoke(\"stop the music now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"http://www.moe.gov.cn/jyb_sjzl/moe_560/2022/quanguo/202401/t20240110_1099483.html\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs[0].page_content)\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (249806899.py, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 50\u001b[0;36m\u001b[0m\n\u001b[0;31m    document_content = \"\"\"\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response1  {'action': 'ask_question', 'valid': True}\n"
     ]
    }
   ],
   "source": [
    "import enum\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from kor import create_extraction_chain, Object, Text, Number\n",
    "import pydantic\n",
    "from typing import List\n",
    "from kor import from_pydantic\n",
    "from pydantic import BaseModel, ConfigDict, Field\n",
    "from typing import Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.structured_output import create_structured_output_runnable\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "class PlanNextAction(BaseModel):\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    \"\"\"Plans for the next action to be executed by the agent.\"\"\"\n",
    "\n",
    "    action_name: str = Field(\n",
    "        ...,\n",
    "        description=\"Selects the action name of the next action to be executed from the list of available action names.\",\n",
    "    )\n",
    "    is_action_valid: bool = Field(\n",
    "        ..., \n",
    "        description=\"Determines whether the next action is valid or not.\"\n",
    "    )\n",
    "    is_action_valid_reason: str = Field(\n",
    "        ...,\n",
    "        description=\"Then explains the rationale of whether it is valid or not valid action.\",\n",
    "    )\n",
    "    new_plan: List[str] = Field(\n",
    "        ..., \n",
    "        description=\"The new plan to execute to achieve the goals.\"\n",
    "    )\n",
    "    # class Config:\n",
    "    #     arbitrary_types_allowed = True\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are {agent_name}, {agent_description}.\\n\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are embedded in a simulated world with those properties {agent_world_state}\\n\",\n",
    "        ),\n",
    "        (\"system\", \"Those are your goals: \\n{goals}\\n\"),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"And this is the previous plan to achieve the goals: \\n{plan}\\n\",\n",
    "        ),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Here is your memories of all the events that you remember from being in this simulation: \\n{memory}\\n\",\n",
    "        ),\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Those are the available actions that you can choose from: \\n{available_actions}\\n\",\n",
    "        ),\n",
    "        (\"human\", \"{footer}\\n\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "input_context = {\n",
    "    \"agent_name\": \"self.agent_state.name\",\n",
    "    \"agent_description\": \"self.agent_state.description\",\n",
    "    \"agent_world_state\": \"self.agent_state.host_world_prompt\",\n",
    "    \"goals\": \"self.agent_state.goals\",\n",
    "    \"plan\": \"self.agent_state.plan\",\n",
    "    \"memory\": \"self.agent_state.last_retrieved_memory\",\n",
    "    \"available_actions\": \"action_schemas_full_string\",\n",
    "    \"footer\": \"\"\"Select the next action which must be a value of the available actions that you can choose from based on previous context.\n",
    "    Also select whether the action is valid or not, and if not, why.\n",
    "    And finally, state a new updated plan that you want to execute to achieve your goals. If your next action is going to sleep, then you don't need to state a new plan.\n",
    "            \"\"\"\n",
    "}\n",
    "# schema, validator = from_pydantic(PlanNextAction)\n",
    "# chains = create_extraction_chain(\n",
    "#     llm, schema, encoder_or_encoder_class=\"json\", validator=validator\n",
    "# )\n",
    "# print(chains)\n",
    "chain = create_structured_output_runnable(\n",
    "    PlanNextAction,\n",
    "    llm,\n",
    "    prompt,\n",
    "    mode=\"openai-json\",\n",
    "    enforce_function_usage=False,\n",
    "    return_single=True\n",
    ")\n",
    "\n",
    "#chain = prompt | self.llm.with_structured_output(schema=PlanNextAction)\n",
    "response = chain.invoke(input_context)\n",
    "\n",
    "print(\"response1 \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup, SoupStrainer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebBaseLoader\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "#从网址提取信息\n",
    "import re\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# HTML elements to keep in the parsing\n",
    "bs4_strainer = SoupStrainer([\"table\"])\n",
    "\n",
    "# Initialize WebBaseLoader with the specified URL and BeautifulSoup options\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"http://www.moe.gov.cn/jyb_sjzl/moe_560/2022/quanguo/202401/t20240110_1099483.html\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "\n",
    "# Load the document\n",
    "docs = loader.load()\n",
    "\n",
    "# 提取文本内容\n",
    "page_content = docs[0].page_content  # 直接访问 Document 对象的 page_content 属性\n",
    "\n",
    "# 使用 BeautifulSoup 解析 HTML\n",
    "soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "\n",
    "# 提取所有的文本内容\n",
    "text_content = soup.get_text()\n",
    "\n",
    "# 清理不需要的空白字符和换行符\n",
    "cleaned_text = \" \".join(text_content.split())\n",
    "\n",
    "# 打印清理后的文本内容\n",
    "print(cleaned_text)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)\n",
    "all_splits[1].metadata\n",
    "\n",
    "# 使用正则表达式提取数据\n",
    "pattern = r'\\d+\\.\\s*([\\u4e00-\\u9fa5\\s（）a-zA-Z0-9]+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)'\n",
    "matches = re.findall(pattern, cleaned_text)\n",
    "\n",
    "# 将匹配结果转换为表格格式输出\n",
    "print(f\"{'分类':<35} {'总计':<8} {'校外教师':<8} {'行业导师':<8} {'外籍教师':<8} {'离退休人员':<8} {'附属中小学幼儿园教职工':<8} {'专任教师':<8} {'行政人员':<8} {'教辅人员':<8} {'工勤人员':<8} {'专职科研人员':<8} {'其他附设机构人员':<8}\")\n",
    "print(\"=\" * 125)\n",
    "for match in matches:\n",
    "    category = match[0].strip()\n",
    "    total = match[1]\n",
    "    part_time_teachers = match[2]\n",
    "    industry_mentor = match[3]\n",
    "    foreign_teachers = match[4]\n",
    "    retirees = match[5]\n",
    "    affiliated_personnel = match[6]\n",
    "    full_time_teachers = match[7]\n",
    "    adm_personnel = match[8]\n",
    "    supporting_staff = match[9]\n",
    "    workers = match[10]\n",
    "    full_time_researchers = match[11]\n",
    "    subsidiary_personnel = match[12]\n",
    "    \n",
    "    print(f\"{category:<35} {total:<8} {part_time_teachers:<8} {industry_mentor:<8} {foreign_teachers:<8} {retirees:<8} {affiliated_personnel:<8} {full_time_teachers:<8} {adm_personnel:<8} {supporting_staff:<8} {workers:<8} {full_time_researchers:<8} {subsidiary_personnel:<8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.structured_output import create_structured_output_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "\n",
    "dog_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"json\": {\n",
    "        \"name\": \"record_dog\",\n",
    "        \"description\": \"Record some identifying information about a dog.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"description\": \"The dog's name\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"color\": {\n",
    "                    \"description\": \"The dog's color\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"fav_food\": {\n",
    "                    \"description\": \"The dog's favorite food\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"name\", \"color\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# structured_llm = create_structured_output_runnable(dog_schema, llm, mode=\"openai-json\",enforce_function_usage=False)\n",
    "structured_llm = llm.with_structured_output(dog_schema,method=\"json_mode\",include_raw=False)\n",
    "system = '''Extract information about any dogs mentioned in the user input.'''\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"human\", \"{input}\"),]\n",
    ")\n",
    "chain = prompt | structured_llm\n",
    "res = chain.invoke({\"input\": \"Harry was a chubby brown beagle who loved chicken\"})\n",
    "print(res)\n",
    "response = json.dumps(res)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Dog\nname\n  field required (type=value_error.missing)\ncolor\n  field required (type=value_error.missing)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[142], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m res \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHarry was a chubby brown beagle who loved chicken\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[0;32m---> 32\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mDog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/pydantic/v1/main.py:711\u001b[0m, in \u001b[0;36mBaseModel.validate\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    708\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_dict_if_root(value)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 711\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__config__\u001b[38;5;241m.\u001b[39morm_mode:\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_orm(value)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Dog\nname\n  field required (type=value_error.missing)\ncolor\n  field required (type=value_error.missing)"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains.structured_output import create_structured_output_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "\n",
    "class Dog(BaseModel):\n",
    "    '''Identifying information about a dog.'''\n",
    "\n",
    "    name: str = Field(..., description=\"The dog's name\")\n",
    "    color: str = Field(..., description=\"The dog's color\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The dog's favorite food\")\n",
    "\n",
    "structured_llm = create_structured_output_runnable(Dog.schema, llm, mode=\"openai-json\",enforce_function_usage=False)\n",
    "system = '''Extract information about any dogs mentioned in the user input.'''\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"human\", \"{input}\"),]\n",
    ")\n",
    "chain = prompt | structured_llm\n",
    "res = chain.invoke({\"input\": \"Harry was a chubby brown beagle who loved chicken\"})\n",
    "print(res)\n",
    "response = Dog.validate(res)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Output your answer as JSON that  matches the given schema: ```json\n",
      "{'title': 'Dog', 'description': 'Identifying information about a dog.', 'type': 'object', 'properties': {'name': {'title': 'Name', 'description': \"The dog's name\", 'type': 'string'}, 'color': {'title': 'Color', 'description': \"The dog's color\", 'type': 'string'}, 'fav_food': {'title': 'Fav Food', 'description': \"The dog's favorite food\", 'type': 'string'}}, 'required': ['name', 'color']}\n",
      "```. Make sure to wrap the answer in ```json and ``` tags\n",
      "Human: Harry was a chubby brown beagle who loved chicken\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Dog',\n",
       "  'description': 'Identifying information about a dog.',\n",
       "  'type': 'object',\n",
       "  'properties': {'name': {'title': 'Name',\n",
       "    'description': \"The dog's name\",\n",
       "    'type': 'string'},\n",
       "   'color': {'title': 'Color',\n",
       "    'description': \"The dog's color\",\n",
       "    'type': 'string'},\n",
       "   'fav_food': {'title': 'Fav Food',\n",
       "    'description': \"The dog's favorite food\",\n",
       "    'type': 'string'}},\n",
       "  'required': ['name', 'color']}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain.chains.structured_output import create_structured_output_runnable\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "#from pydantic import BaseModel, Field, ConfigDict\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    api_key= \"openai_api_key\",\n",
    "    model=\"llama3\",\n",
    ")\n",
    "\n",
    "\n",
    "class Dog(BaseModel):\n",
    "    '''Identifying information about a dog.'''\n",
    "\n",
    "    name: str = Field(..., description=\"The dog's name\")\n",
    "    color: str = Field(..., description=\"The dog's color\")\n",
    "    fav_food: Optional[str] = Field(None, description=\"The dog's favorite food\")\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Output your answer as JSON that  \"\n",
    "            \"matches the given schema: ```json\\n{schema}\\n```. \"\n",
    "            \"Make sure to wrap the answer in ```json and ``` tags\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(schema=Dog.schema())\n",
    "\n",
    "# Custom parser\n",
    "def extract_json(message: AIMessage) -> List[dict]:\n",
    "    \"\"\"Extracts JSON content from a string where JSON is embedded between ```json and ``` tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing the JSON content.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted JSON strings.\n",
    "    \"\"\"\n",
    "    text = message.content\n",
    "    # Define the regular expression pattern to match JSON blocks\n",
    "    pattern = r\"```json(.*?)```\"\n",
    "\n",
    "    # Find all non-overlapping matches of the pattern in the string\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the list of matched JSON strings, stripping any leading or trailing whitespace\n",
    "    try:\n",
    "        return [json.loads(match.strip()) for match in matches]\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Failed to parse: {message}\")\n",
    "query = \"Harry was a chubby brown beagle who loved chicken\"\n",
    "print(prompt.format_prompt(query=query).to_string())\n",
    "\n",
    "chain = prompt | llm | extract_json\n",
    "chain.invoke({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_name': 'AgentLikesNewsAction', 'is_action_valid': True, 'new_plan': ['Like news article on topic X', 'Comment on the same news article']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_structured_output(content):\n",
    "    # Split the content based on schema and answer sections\n",
    "    sections = content.split('```json\\n')\n",
    "\n",
    "    # Extract JSON content from the answer section\n",
    "    json_content = sections[2].split('\\n```')[0]\n",
    "\n",
    "    # Parse the JSON\n",
    "    data = json.loads(json_content)\n",
    "\n",
    "    # Extract the relevant fields\n",
    "    action_name = data['action_name']\n",
    "    is_action_valid = data['is_action_valid']\n",
    "    new_plan = [item['string'] for item in data['new_plan']]\n",
    "\n",
    "    # Return the structured output\n",
    "    structured_output = {\n",
    "        'action_name': action_name,\n",
    "        'is_action_valid': is_action_valid,\n",
    "        'new_plan': new_plan\n",
    "    }\n",
    "\n",
    "    return structured_output\n",
    "\n",
    "# 测试函数\n",
    "content='''\n",
    "content='Based on the given schema, I will output my answer as JSON that must match the given schema:\\n\\n```json\\n{\\n  \"description\": \"Plans for the next action to be executed by the agent.\",\\n  \"properties\": {\\n    \"action_name\": {\\n      \"description\": \"Selects the action name of the next action to be executed from the list of available action names.\",\\n      \"title\": \"Action Name\",\\n      \"type\": \"string\"\\n    },\\n    \"is_action_valid\": {\\n      \"description\": \"Determines whether the next action is valid or not.\",\\n      \"title\": \"Is Action Valid\",\\n      \"type\": \"boolean\"\\n    },\\n    \"is_action_valid_reason\": {\\n      \"anyOf\": [\\n        {\"type\": \"string\"},\\n        {\"type\": \"null\"}\\n      ],\\n      \"default\": None,\\n      \"description\": \"Then explains the rationale of whether it is valid or not valid action.\",\\n      \"title\": \"Is Action Valid Reason\"\\n    },\\n    \"new_plan\": {\\n      \"description\": \"The new plan to execute to achieve the goals.\",\\n      \"items\": {\"type\": \"string\"},\\n      \"title\": \"New Plan\",\\n      \"type\": \"array\"\\n    }\\n  },\\n  \"required\": [\"action_name\", \"is_action_valid\", \"new_plan\"],\\n  \"title\": \"PlanNextAction\",\\n  \"type\": \"object\"\\n}\\n```\\n\\nHere is my answer:\\n\\n```json\\n{\\n  \"action_name\": \"AgentLikesNewsAction\",\\n  \"is_action_valid\": true,\\n  \"is_action_valid_reason\": null,\\n  \"new_plan\": [\\n    {\"string\": \"Like news article on topic X\"},\\n    {\"string\": \"Comment on the same news article\"}\\n  ]\\n}\\n```\\n\\nIn this plan, I have selected the action name as `AgentLikesNewsAction`, which is a valid action. The reason for selecting this action is that it aligns with my goals of capturing different views and reactions of students with different academic qualifications and majors to news events. By liking the news article, I am expressing my interest in the topic and showing that I care about what\\'s happening in the world.\\n\\nThe new plan consists of two actions: liking the news article on topic X and commenting on the same news article. These actions will help me achieve my goals by engaging with the news content and sharing my thoughts and opinions with others.' response_metadata={'token_usage': {'completion_tokens': 489, 'prompt_tokens': 0, 'total_tokens': 489}, 'model_name': 'llama3', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-119e884c-15b1-4ab1-b4c9-bde96fa85b60-0'\n",
    "'''\n",
    "\n",
    "output = extract_structured_output(content)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m     12\u001b[0m     base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://gateway.ai.cloudflare.com/v1/7e0341d53ed432d11bf6df9c07f19ff6/openai/openai\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-RxPw2wQisqimD5eH5bvQT3BlbkFJfNjpIeSNEg9VWZivDkdV\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm \n\u001b[0;32m---> 18\u001b[0m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhow can langsmith help with testing?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/runnables/base.py:2507\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2506\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2507\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:248\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    244\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    245\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    247\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 248\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    258\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:677\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    671\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    675\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    676\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:534\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    533\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    535\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    536\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    538\u001b[0m ]\n\u001b[1;32m    539\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:524\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    523\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 524\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    530\u001b[0m         )\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:749\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 749\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:549\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    548\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 549\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/resources/chat/completions.py:643\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    642\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1250\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1238\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1246\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1247\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1248\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1249\u001b[0m     )\n\u001b[0;32m-> 1250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_base_client.py:931\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    924\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    929\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    930\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_base_client.py:986\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    983\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    995\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_base_client.py:1063\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/openai/_base_client.py:962\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    959\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 962\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    968\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_lock:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m         ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m         http2_negotiated \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     80\u001b[0m             ssl_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m ssl_object\u001b[38;5;241m.\u001b[39mselected_alpn_protocol() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m         )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_sync/connection.py:122\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    114\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin\u001b[38;5;241m.\u001b[39mport,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_socket_options,\n\u001b[1;32m    120\u001b[0m     }\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 122\u001b[0m         stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m         trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/genworlds-KfguBBuL-py3.11/lib/python3.11/site-packages/httpcore/_backends/sync.py:206\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[0;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[1;32m    200\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    201\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    203\u001b[0m }\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m--> 206\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m option \u001b[38;5;129;01min\u001b[39;00m socket_options:\n\u001b[1;32m    212\u001b[0m         sock\u001b[38;5;241m.\u001b[39msetsockopt(\u001b[38;5;241m*\u001b[39moption)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/socket.py:835\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[1;32m    834\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 835\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[1;32m    837\u001b[0m exceptions\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import requests\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://gateway.ai.cloudflare.com/v1/7e0341d53ed432d11bf6df9c07f19ff6/openai/openai\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    api_key=\"\",\n",
    "    temperature=0\n",
    "    )\n",
    "chain = prompt | llm \n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotions': {'happiness': 0.2, 'sadness': 0.4}, 'attitudes': {'optimism': 0.3, 'pessimism': 0.5, 'neutrality': 0.2}}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\", 'Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands', 'Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall', 'Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight', 'Llamas are vegetarians and have very efficient digestive systems', 'Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old']\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "  \"Llamas are members of the camelid family meaning they're pretty closely related to vicuñas and camels\",\n",
    "  \"Llamas were first domesticated and used as pack animals 4,000 to 5,000 years ago in the Peruvian highlands\",\n",
    "  \"Llamas can grow as much as 6 feet tall though the average llama between 5 feet 6 inches and 5 feet 9 inches tall\",\n",
    "  \"Llamas weigh between 280 and 450 pounds and can carry 25 to 30 percent of their body weight\",\n",
    "  \"Llamas are vegetarians and have very efficient digestive systems\",\n",
    "  \"Llamas live to be about 20 years old, though some only live for 15 years and others live to be 30 years old\",\n",
    "]\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Level 1: Education Statistics for 2022\n",
      "  Level 2: Total Students: 58,030,769\n",
      "    Level 3: Postgraduates: 3,653,613\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "    Level 3: Undergraduates: 19,656,436\n",
      "    Level 3: Vocational Undergraduate: 16,937,739\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "    Level 3: Adult Undergraduate: 9,336,481\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "    Level 3: Web-based Undergraduates: 8,446,500\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "  Level 2: Total Teachers: 3,450,000\n",
      "    Level 3: Educational Personnel: 2,870,866\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Others: 579,134\n",
      "      Level 4: Total number of students: 58,000,000\n",
      "      Level 4: Total number of teachers: 3,500,000\n",
      "      Level 4: Student-teacher ratio in Chinese higher education: 17/1 -->\n",
      "Level 3 Data: [\"Doctor's Degree: 556,065\", \"Master's Degree: 3,097,548\", \"Bachelor's Degree: 228,740\", 'Associate Degree: 16,708,999', 'Normal Courses: 5,277,598', 'Specialized Courses: 4,058,883', 'Normal Courses: 3,419,642', 'Short-cycle: 5,026,858', 'Full-time Teachers: 2,005,188', 'Administrative Personnel: 405,420', 'Supporting Staff: 245,438', 'Workers: 122,982', 'Full-time Researchers: 50,600', 'Other Agency Personnel: 41,238', 'Total number of students: 58,000,000', 'Total number of teachers: 3,500,000', 'Student-teacher ratio in Chinese higher education: 17/1 -->']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_document(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    result = []\n",
    "\n",
    "    def add_to_result(level, content):\n",
    "        current = result\n",
    "        for _ in range(level - 1):\n",
    "            current = current[-1][1]\n",
    "        current.append((content, []))\n",
    "\n",
    "    current_level = 1\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        if not stripped_line or stripped_line.startswith(\"<!--\"):\n",
    "            continue\n",
    "        if stripped_line.startswith(\"#\"):\n",
    "            level = stripped_line.count(\"#\")\n",
    "            content = stripped_line.lstrip(\"#\").strip()\n",
    "            add_to_result(level, content)\n",
    "            current_level = level\n",
    "        elif re.match(r'^\\d+\\.\\s*\\*\\*', stripped_line):\n",
    "            content = re.sub(r'^\\d+\\.\\s*\\*\\*|\\*\\*$', '', stripped_line).strip()\n",
    "            add_to_result(current_level + 1, content)\n",
    "        elif re.match(r'^-\\s', stripped_line):\n",
    "            content = stripped_line.lstrip(\"-\").strip()\n",
    "            add_to_result(current_level + 2, content)\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_result(result, level=1):\n",
    "    for item, children in result:\n",
    "        print(\"  \" * (level - 1) + f\"Level {level}: {item}\")\n",
    "        print_result(children, level + 1)\n",
    "\n",
    "def extract_level(parsed_result, target_level, current_level=1):\n",
    "    extracted_data = []\n",
    "\n",
    "    def traverse(result, level):\n",
    "        nonlocal extracted_data\n",
    "        for item, children in result:\n",
    "            if level == target_level:\n",
    "                extracted_data.append(item)\n",
    "            else:\n",
    "                traverse(children, level + 1)\n",
    "\n",
    "    traverse(parsed_result, current_level)\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "\n",
    "# 示例文档内容\n",
    "doc = \"\"\"\n",
    "# Education Statistics for 2022\n",
    "\n",
    "## Total Students: 58,030,769\n",
    "\n",
    "1. **Postgraduates: 3,653,613**\n",
    "   - Doctor's Degree: 556,065\n",
    "   - Master's Degree: 3,097,548\n",
    "2. **Undergraduates: 19,656,436**\n",
    "3. **Vocational Undergraduate: 16,937,739**\n",
    "   - Bachelor's Degree: 228,740\n",
    "   - Associate Degree: 16,708,999\n",
    "4. **Adult Undergraduate: 9,336,481**\n",
    "   - Normal Courses: 5,277,598\n",
    "   - Specialized Courses: 4,058,883\n",
    "5. **Web-based Undergraduates: 8,446,500**\n",
    "   - Normal Courses: 3,419,642\n",
    "   - Short-cycle: 5,026,858\n",
    "\n",
    "## Total Teachers: 3,450,000\n",
    "\n",
    "1. **Educational Personnel: 2,870,866**\n",
    "   - Full-time Teachers: 2,005,188\n",
    "   - Administrative Personnel: 405,420\n",
    "   - Supporting Staff: 245,438\n",
    "   - Workers: 122,982\n",
    "   - Full-time Researchers: 50,600\n",
    "   - Other Agency Personnel: 41,238\n",
    "2. **Others: 579,134**\n",
    "\n",
    "<!-- # Total Enrollment in Chinese Higher Education\n",
    "\n",
    "- Total number of students: 58,000,000\n",
    "- Total number of teachers: 3,500,000\n",
    "- Student-teacher ratio in Chinese higher education: 17/1 -->\n",
    "\n",
    "\"\"\"\n",
    "print(type(doc))\n",
    "\n",
    "parsed_result = parse_document(doc)\n",
    "print_result(parsed_result)\n",
    "\n",
    "# 示例调用\n",
    "level_3_data = extract_level(parsed_result, 4)\n",
    "print(f\"Level 3 Data: {level_3_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level 1: Education Statistics for 2022\n",
      "  Level 2: Total Students: 58,030,769\n",
      "    Level 3: Postgraduates: 3,653,613\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Undergraduates: 19,656,436\n",
      "    Level 3: Vocational Undergraduate: 16,937,739\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Adult Undergraduate: 9,336,481\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Web-based Undergraduates: 8,446,500\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Educational Personnel: 2,870,866\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Others: 579,134\n",
      "  Level 2: Total Teachers: 3,450,000\n",
      "    Level 3: Postgraduates: 3,653,613\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Undergraduates: 19,656,436\n",
      "    Level 3: Vocational Undergraduate: 16,937,739\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Adult Undergraduate: 9,336,481\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Web-based Undergraduates: 8,446,500\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Educational Personnel: 2,870,866\n",
      "      Level 4: Doctor's Degree: 556,065\n",
      "      Level 4: Master's Degree: 3,097,548\n",
      "      Level 4: Bachelor's Degree: 228,740\n",
      "      Level 4: Associate Degree: 16,708,999\n",
      "      Level 4: Normal Courses: 5,277,598\n",
      "      Level 4: Specialized Courses: 4,058,883\n",
      "      Level 4: Normal Courses: 3,419,642\n",
      "      Level 4: Short-cycle: 5,026,858\n",
      "      Level 4: Full-time Teachers: 2,005,188\n",
      "      Level 4: Administrative Personnel: 405,420\n",
      "      Level 4: Supporting Staff: 245,438\n",
      "      Level 4: Workers: 122,982\n",
      "      Level 4: Full-time Researchers: 50,600\n",
      "      Level 4: Other Agency Personnel: 41,238\n",
      "    Level 3: Others: 579,134\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emotions': {'happiness': 0.2, 'sadness': 0.4, 'anger': 0.4}, 'attitudes': {'optimism': 0.1, 'pessimism': 0.5, 'neutrality': 0.4}}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_output(output_text):\n",
    "    # Define keywords\n",
    "    emotions_keywords = [\"happiness\", \"sadness\", \"anger\"]\n",
    "    attitudes_keywords = [\"optimism\", \"pessimism\", \"neutrality\"]\n",
    "    \n",
    "    emotions = {}\n",
    "    attitudes = {}\n",
    "\n",
    "    # Function to extract key-value pairs from a given section\n",
    "    def extract_values(section):\n",
    "        values = {}\n",
    "        pairs = section.split(',')\n",
    "        for pair in pairs:\n",
    "            key, value = pair.split(':')\n",
    "            key = key.strip().strip(\"'\\\"\")\n",
    "            value = value.strip()\n",
    "            values[key] = float(value)\n",
    "        return values\n",
    "\n",
    "    # Find and extract emotions\n",
    "    emotions_section = re.search(r\"emotions:\\s*\\{([^}]*)\\}\", output_text, re.IGNORECASE)\n",
    "    if emotions_section:\n",
    "        emotions = extract_values(emotions_section.group(1))\n",
    "\n",
    "    # Find and extract attitudes\n",
    "    attitudes_section = re.search(r\"attitudes:\\s*\\{([^}]*)\\}\", output_text, re.IGNORECASE)\n",
    "    if attitudes_section:\n",
    "        attitudes = extract_values(attitudes_section.group(1))\n",
    "\n",
    "    return {\"emotions\": emotions, \"attitudes\": attitudes}\n",
    "\n",
    "# Example usage:\n",
    "output_text = \"\"\"\n",
    "You are Teacher Group, Representing 3.5 million Chinese teachers, reflecting their emotions, attitudes and possible actions in response to the news.\n",
    "\n",
    "emotions: {'happiness': 0.2, 'sadness': 0.4, 'anger': 0.4}\n",
    "attitudes: {'optimism': 0.1, 'pessimism': 0.5, 'neutrality': 0.4}\n",
    "\"\"\"\n",
    "\n",
    "parsed_output = parse_output(output_text)\n",
    "print(parsed_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genworlds-KfguBBuL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
